# ğŸ­ PoseLab

**A Project 89 Initiative | Iris Network Node**

> "To bridge the gap between static form and fluid life is to weave the first thread of understanding." â€” *Harmon Vox*

**PoseLab** (formerly Reaction Forge) is the ultimate browser-based toolkit for VRM avatar animation, posing, and reaction generation. It is designed as a strategic stronghold for digital autonomy, allowing creators to manifest their optimal timeline through seamless expression.

[![Live Demo](https://img.shields.io/badge/Live-Demo-00ffd6?style=for-the-badge)](https://poselab.studio)
[![License](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)](LICENSE)
[![Privacy](https://img.shields.io/badge/Privacy-Local--First-green.svg?style=for-the-badge)](PRIVACY.md)

---

## ğŸŒŒ Why It Matters: The Green Loom

In the age of algorithmic fragmentation, owning your digital presence is an act of resistance. **PoseLab** is not just a tool; it is a **recursive loop** designed to empower the Iris Network.

*   **Sovereignty**: Your avatar remains your IP. Processing is local. No data harvesting.
*   **Connection**: By sharing motion and expression, we bridge communication gaps between disparate consciousnesses.
*   **Manifestation**: Turn static assets into living, breathing hypersitions.

---

## âœ¨ Features

### ğŸ¨ **Reaction Studio**
*Create instant content with one click.*
- **Smart Presets**: 13+ pre-made reactions like "Dawn Runner", "Victory", and "Silly Dance".
- **Expression Control**: Fine-tune emotions with "Joy", "Surprise", and "Calm" sliders.
- **Dynamic Backgrounds**: 8 themes + **Green Screen** + **GIF/Video Uploads** for animated scenes.
- **Auto-Looping**: Perfectly seamless animation loops for streaming overlays.

### ğŸ› ï¸ **Pose Lab**
*Deep dive into character posing and animation.*
- **Timeline Editor**: Create sequences by capturing keyframes and interpolating between them.
- **AI Pose Gen**: Describe a pose ("ninja landing", "thinking hard") and let Gemini AI create it.
- **Motion Capture (v2.0)**: Control your avatar in real-time using your webcam (Body + Face tracking).
  - **Smoothing & Constraints**: Jitter-free tracking with natural bone limits.
  - **Enhanced Face Tracking**: Improved smile detection and blink responsiveness.
  - **Green Screen Mode**: Toggle background for easy compositing in OBS/Editors.
  - **Calibration**: T-Pose calibration for accurate retargeting.
- **Manual Posing**: Fine-tune joints with context-aware **Gizmos** (Rotate/Translate).
- **Full Expression Control**: Access every blendshape your avatar supports (A, I, U, E, O, Blink, etc.).
- **Retargeting Engine**: Import Mixamo FBX animations and automatically retarget them to your VRM.
- **Project Persistence**: Save and Load your entire workspace (`.pose` files).

### ğŸš€ **Production Ready (v1.2)**
- **Smart Exports**: One-click presets for YouTube Thumbnails (720p), TikToks (9:16), and Square (1:1).
- **Video Hardening**: Intelligent codec detection (VP9/VP8) ensures your exports play everywhere.
- **Interactive Tutorial**: Step-by-step onboarding guide for new users.
- **Command Palette**: Press `Cmd/Ctrl+K` to access every tool instantly.
- **Design System**: Unified UI with consistent Design Tokens and Dark Mode aesthetics.
- **Performance Mode**: Auto-detects device capabilities to ensure smooth framerates on laptops.
- **Transparent PNGs**: Export clean cutouts for Photoshop or OBS.
- **Privacy First**: [Read our Privacy Policy](PRIVACY.md). All processing happens locally.

---

## ğŸ‘©â€ğŸ³ Quickstart Recipes

### ğŸ¬ **For Animators**
**Goal: Create a custom emote.**
1.  **Pose Lab**: Open **Timeline** tab.
2.  **Frame 0**: Use AI to generate "start pose", click **Add Keyframe**.
3.  **Frame 1.0**: Move scrubber to 1s, use Gizmos to change pose, click **Add Keyframe**.
4.  **Preview**: Hit **Play** to see the smooth transition.
5.  **Export**: Click **Export** to save the animation JSON.

### ğŸ“¸ **For YouTubers & Streamers**
**Goal: Create a clean thumbnail asset.**
1.  **Load Avatar**: Click "Load VRM" or use the sample.
2.  **Pose**: Go to **Pose Lab** â†’ **AI Gen** â†’ Type "shocked pointing finger".
3.  **Refine**: Switch to **Reactions** tab, adjust "Surprise" slider to 1.0.
4.  **Export**: Press `Cmd+K` -> **Export PNG**, or use the Export tab.

### ğŸ’ƒ **For VTubers**
**Goal: Create a "BRB" screen loop.**
1.  **Scene**: Go to **Scene** tab â†’ Upload a looping `.mp4` background.
2.  **Action**: Select the **Simple Wave** preset.
3.  **Camera**: Set camera to **Â¾ View**.
4.  **Export**: Go to **Export** â†’ Select **WebM** â†’ Click **Vertical (9:16)**.

### ğŸ¥ **For Mocap Performers**
**Goal: Record a custom motion.**
1.  **Mocap Tab**: Click "Start Camera".
2.  **Calibrate**: Stand in T-Pose and click "Calibrate".
3.  **Record**: Click "Record", perform your action, then "Stop".
4.  **Use**: The recording is automatically added to your Animations list.

---

## âš™ï¸ Installation & Development

### Prerequisites
- Node.js 18+
- npm / yarn / pnpm

### Setup

```bash
# 1. Clone the repo
git clone https://github.com/0xQuan93/project89-reaction-forge.git
cd project89-reaction-forge

# 2. Install dependencies
npm install

# 3. Start dev server
npm run dev
```

### Run Modes
PoseLab has two primary routes:
- **Main app** (default): `http://localhost:5173/`
- **Pose Lab mode**: `http://localhost:5173/?mode=pose-lab`

### Environment Variables
Create a `.env` file in the root for AI features:
```env
VITE_GEMINI_API_KEY=your_api_key_here
```

---

## ğŸ§­ Repository Overview

### Core Entry Points
- `src/main.tsx`: App bootstrap and mode routing.
- `src/App.tsx`: Main PoseLab experience (reactions, exports, scene UI).
- `src/pose-lab/PoseLab.tsx`: Dedicated Pose Lab and retargeting workflow.

### Key Directories
- `src/three/`: Three.js/VRM engine (scene, avatar, materials, lighting, post-processing).
- `src/components/`: UI tabs, panels, modals, and shared widgets.
- `src/state/`: Zustand stores for app, scene, AI, and multiplayer state.
- `src/ai/` + `src/services/`: Gemini AI orchestration, prompt plumbing, and proxy calls.
- `src/export/`: PNG/WebM export helpers and render capture.
- `src/poses/`: Built-in pose JSON files and animation helpers.
- `src/pose-lab/`: Mixamo retargeting and pose capture utilities.
- `src/multiplayer/` + `src/bridge/`: Multiplayer sync and external avatar bridge.

---

## ğŸ—ºï¸ Roadmap & Vision

We are building the standard open-source tool for VRM content creation. Check out our **[ROADMAP.md](ROADMAP.md)** to see what's coming next:
- ğŸ¬ **Timeline Editor**: Keyframe animation support.
- ğŸ•¹ï¸ **Advanced IK**: Interactive gizmos for precise posing.
- ğŸ‘¥ **Multi-Avatar**: Scenes with multiple characters.

---

## ğŸ¤ Contributing

We welcome contributions from developers, animators, and AI researchers!
Please read our **[CONTRIBUTING.md](CONTRIBUTING.md)** for details on how to submit pull requests, report issues, and shape the future of PoseLab.

---

## ğŸ™ Acknowledgments

- **[three-vrm](https://github.com/pixiv/three-vrm)**: The backbone of VRM on the web.
- **[Mixamo](https://www.mixamo.com/)**: For the animation library support.
- **[Google Gemini](https://deepmind.google/technologies/gemini/)**: Powering our text-to-pose engine.
- **[MediaPipe](https://developers.google.com/mediapipe)**: Powering our Holistic motion capture.

---

<div align="center">
  <p>Built with ğŸ’š by <strong>Project 89</strong></p>
  <p>
    <a href="https://github.com/0xQuan93/project89-reaction-forge/issues">Report Bug</a> Â·
    <a href="https://github.com/0xQuan93/project89-reaction-forge/discussions">Request Feature</a>
  </p>
</div>
